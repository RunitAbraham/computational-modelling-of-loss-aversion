{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c980b8-4ee7-4be1-ac87-4e88eb653234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hddm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d93334f5-651c-4e3f-a30f-96188bbc1f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "911b280a-a8b8-45e2-8bbe-ad4306f5e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'ep5'\n",
    "m = hddm.load('savedModels/{}/{}'.format(modelName, modelName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f7db752-242f-4eb8-a4aa-9e7478b07bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         mean       std      2.5q       25q       50q       75q     97.5q    mc err\n",
      "a                    2.296469  0.073716  2.159938  2.247548  2.294192  2.343537  2.445431  0.002074\n",
      "a_std                0.463373  0.060892   0.35954  0.420963    0.4572  0.500959   0.60326  0.001779\n",
      "a_subj.1             2.338602  0.130626  2.098486  2.249451  2.335693  2.424153  2.603995  0.003565\n",
      "a_subj.2             1.982984  0.129587   1.74486  1.893346  1.980423  2.069959  2.245924  0.004506\n",
      "a_subj.3             3.033928   0.19837  2.668435  2.898547  3.026693   3.15712  3.450593   0.00586\n",
      "a_subj.4             2.125917  0.115856  1.918885  2.046307  2.120514  2.198391  2.377818  0.003379\n",
      "a_subj.5             1.900796  0.296195  1.399464  1.688946  1.873166  2.076409  2.543422  0.010807\n",
      "a_subj.6             2.309437  0.276743  1.891292  2.118151  2.270845  2.448839  2.986168  0.014929\n",
      "a_subj.7             2.229103   0.27604  1.756688   2.04311  2.207613  2.386649  2.825192  0.014016\n",
      "a_subj.8             2.220988  0.118565   1.99991  2.141055   2.21503  2.297651  2.466399  0.003666\n",
      "a_subj.9             3.212916   0.23516  2.804482   3.04506   3.19953  3.359433  3.718434  0.007272\n",
      "a_subj.10             3.60753  0.193784  3.245291  3.472252  3.599163  3.732082  4.013903  0.004909\n",
      "a_subj.11            2.293775  0.123502  2.060665  2.209684  2.290797   2.37646  2.548594   0.00342\n",
      "a_subj.12            2.458862  0.113899  2.249865  2.378938  2.453984  2.535431  2.698753  0.003024\n",
      "a_subj.13            1.951953    0.1061   1.75948  1.877242  1.949833  2.019633  2.174237  0.002911\n",
      "a_subj.14            2.129068  0.125173  1.899326  2.043966   2.12104  2.213134  2.388199  0.003132\n",
      "a_subj.15            2.437504  0.121863  2.211851  2.353612  2.432289  2.519809  2.685928  0.003356\n",
      "a_subj.16            2.244295   0.14844  1.986409  2.140433   2.23146  2.333568  2.578422  0.005725\n",
      "a_subj.17            2.016383  0.269283  1.607586  1.831596  1.974747   2.16629  2.656231  0.014854\n",
      "a_subj.18            2.359285  0.123568  2.134289  2.270905  2.354365  2.441359  2.616429  0.004106\n",
      "a_subj.19            1.768252  0.105164  1.571868  1.696246  1.765741   1.83698  1.983019  0.002603\n",
      "a_subj.20            2.107052  0.380313   1.44255  1.839245    2.0876  2.338197  2.940678  0.011197\n",
      "a_subj.21            1.773608  0.107794  1.578034  1.699524  1.765162  1.841398  2.008313  0.003358\n",
      "a_subj.22            1.997621  0.150907   1.72741  1.892777  1.988675  2.090673  2.317176  0.005111\n",
      "a_subj.23            1.855236    0.1224  1.634756  1.771882  1.849594   1.93471  2.110449   0.00417\n",
      "a_subj.24            1.968869  0.356265  1.344595     1.718  1.942408  2.188706  2.743648  0.013186\n",
      "a_subj.25            1.769311  0.090219  1.603671  1.707259  1.764996  1.827655  1.959107  0.002288\n",
      "a_subj.26            2.000716  0.107952  1.802795  1.925653  1.994647  2.070107  2.226161  0.003555\n",
      "a_subj.27            3.259588  0.200718  2.880029  3.125899  3.252433  3.389051  3.671084  0.006892\n",
      "a_subj.28            2.438522  0.127774   2.19646  2.350889  2.434459  2.525243   2.69979  0.003868\n",
      "a_subj.29            2.713065  0.292425  2.223955  2.505316  2.689734  2.888674  3.348242  0.011908\n",
      "a_subj.30            2.474788  0.226673  2.087684   2.31901  2.450252  2.608475  2.977088  0.009489\n",
      "a_subj.31            1.876741  0.119097  1.655391  1.794491   1.87334  1.955448  2.120487  0.003607\n",
      "a_subj.32            1.965059   0.17619  1.652531  1.844113  1.955822  2.073204  2.343744   0.00653\n",
      "a_subj.33            2.719134  0.284047  2.232147  2.522441  2.691232  2.886368  3.369409  0.013733\n",
      "a_subj.34            2.492552  0.136755  2.237167   2.39735  2.486988  2.588708  2.770179  0.004602\n",
      "a_subj.35            1.736545  0.089834  1.564641  1.677158  1.733489  1.796555  1.922124  0.002326\n",
      "a_subj.36            2.273841  0.296983  1.791387  2.058034  2.233527  2.465796  2.938118  0.016774\n",
      "a_subj.37            2.233552  0.107653  2.032386  2.157089  2.230834  2.307306  2.454114  0.002705\n",
      "a_subj.38            2.627045  0.244617   2.21616  2.456935  2.608226  2.780422  3.175421  0.009947\n",
      "a_subj.39            1.590399  0.073753  1.448341  1.540915  1.590055  1.637301  1.742577   0.00196\n",
      "a_subj.40            2.418821  0.126159  2.178054  2.334481  2.414554  2.499587  2.680237  0.003416\n",
      "a_subj.41            2.088446  0.147731  1.820618  1.985704  2.082649  2.177483  2.414494  0.004654\n",
      "a_subj.42            3.001942  0.313375  2.471273  2.775232  2.967127  3.199669  3.703498   0.01621\n",
      "a_subj.43            2.227277  0.105754  2.033056  2.153837  2.224535  2.294969  2.446958  0.002317\n",
      "a_subj.44             2.08933  0.114352  1.876469  2.010572  2.083935  2.165689   2.32252  0.003678\n",
      "a_subj.45            2.400693   0.11949  2.173046  2.318606  2.396674  2.480755  2.646525  0.002685\n",
      "a_subj.46            3.021584  0.276785  2.547921  2.823746  2.997576  3.190635  3.640622   0.01092\n",
      "a_subj.47             2.26316  0.149177  1.988508   2.16168  2.255307  2.359081  2.583168  0.004502\n",
      "a_subj.48            2.342796  0.303543   1.84191  2.122902  2.307805  2.529808   3.03127  0.017842\n",
      "a_subj.49            2.259975  0.126811  2.017416  2.173072  2.257456  2.344153  2.517413  0.003138\n",
      "t                    0.434076  0.018985  0.397384  0.421518   0.43374  0.446401  0.473044  0.000357\n",
      "t_std                0.127021  0.015215  0.101087  0.116261  0.125564  0.136218  0.160679  0.000335\n",
      "t_subj.1             0.489541  0.031234  0.426774  0.468398  0.489955  0.512732  0.545634   0.00087\n",
      "t_subj.2             0.510652  0.038032  0.435662  0.481184  0.514543  0.541663  0.576957  0.002062\n",
      "t_subj.3             0.384692  0.031289  0.317766  0.365363  0.387828  0.406594   0.43658  0.001055\n",
      "t_subj.4             0.663568   0.02523  0.605031  0.648956  0.666589   0.68154  0.704737  0.000688\n",
      "t_subj.5              0.34032  0.024982  0.279851  0.327059  0.343747  0.358414  0.377789  0.001216\n",
      "t_subj.6              0.32724  0.023237  0.272817   0.31421  0.330024  0.344232  0.363318  0.001227\n",
      "t_subj.7              0.32968  0.019708  0.286458  0.317647   0.33109  0.344034  0.363082   0.00095\n",
      "t_subj.8             0.457314  0.023493  0.410012  0.442071  0.457912  0.474772  0.499671  0.000684\n",
      "t_subj.9             0.479649  0.060522  0.364807  0.437458  0.476493  0.523787  0.591544  0.002353\n",
      "t_subj.10            0.279496  0.045624  0.184801  0.248922  0.281285  0.311539   0.36433  0.001114\n",
      "t_subj.11            0.509792  0.025681  0.453168  0.494222  0.512352  0.527878  0.553396  0.000809\n",
      "t_subj.12             0.35519   0.01947  0.312024  0.343177  0.357383  0.369083  0.387049  0.000439\n",
      "t_subj.13             0.47318  0.015787  0.438712  0.463504  0.474409  0.484593  0.500005  0.000481\n",
      "t_subj.14            0.527536  0.025325   0.47299  0.511699  0.528652  0.544457  0.574613   0.00088\n",
      "t_subj.15            0.916442  0.032701  0.843502  0.896955  0.918765  0.939648  0.970781  0.001015\n",
      "t_subj.16            0.454498  0.046758  0.336618  0.439323  0.468468  0.486316   0.51091  0.002468\n",
      "t_subj.17            0.368241  0.012011  0.340987  0.360988  0.369745  0.376968  0.387816  0.000579\n",
      "t_subj.18            0.555547  0.024387  0.500849  0.539877  0.557293  0.573066  0.597665  0.000814\n",
      "t_subj.19            0.312522   0.02373  0.261066  0.298345  0.314694   0.32932  0.352564  0.000625\n",
      "t_subj.20            0.358005  0.054903  0.239073  0.322875  0.363632  0.398451  0.447736  0.001833\n",
      "t_subj.21            0.363159  0.014064  0.332963  0.355103  0.364121  0.372379  0.387792  0.000491\n",
      "t_subj.22            0.357143  0.012723  0.328308  0.349797  0.358661  0.366019  0.378208  0.000571\n",
      "t_subj.23             0.37154  0.023538  0.332714   0.35521  0.368274  0.384875  0.427829   0.00091\n",
      "t_subj.24            0.329695  0.034261  0.253229  0.309115  0.333257  0.354775  0.383779  0.001454\n",
      "t_subj.25            0.381935  0.015593  0.346369  0.373133   0.38329  0.392506  0.408568  0.000424\n",
      "t_subj.26             0.50981  0.020936  0.461594  0.497347  0.512353  0.524907  0.543606  0.000634\n",
      "t_subj.27            0.587076  0.045599  0.491421  0.557469  0.589546  0.618756  0.669737  0.001414\n",
      "t_subj.28            0.463651   0.02677  0.408884  0.446678   0.46466  0.481794  0.513921   0.00073\n",
      "t_subj.29             0.31116  0.027274   0.25046  0.294452  0.313588  0.330419  0.357304   0.00118\n",
      "t_subj.30            0.312719   0.02659  0.248695  0.297337  0.315788  0.331897  0.355124  0.001225\n",
      "t_subj.31            0.370317  0.014559  0.338931  0.361745  0.371188  0.380053  0.396095  0.000563\n",
      "t_subj.32            0.363265  0.012798  0.335805  0.355688  0.364537  0.372349  0.384382  0.000522\n",
      "t_subj.33            0.327851  0.027327  0.266185  0.312286  0.331077  0.347468  0.371712  0.001315\n",
      "t_subj.34            0.386695  0.023649  0.334874  0.372051  0.388841  0.403371    0.4274  0.000592\n",
      "t_subj.35            0.614222  0.016505  0.577381  0.604077   0.61572  0.626227  0.642442  0.000437\n",
      "t_subj.36            0.311706  0.024339    0.2544  0.297967  0.314373  0.329157  0.350595  0.001388\n",
      "t_subj.37            0.760381  0.027567  0.702561   0.74189  0.761528  0.780169  0.808978  0.000632\n",
      "t_subj.38             0.48959  0.025667  0.430842  0.473591  0.492994  0.508058  0.531804  0.001107\n",
      "t_subj.39            0.528424  0.018645  0.496188  0.515953   0.52637  0.538654  0.571464  0.000528\n",
      "t_subj.40             0.58573  0.027487  0.527031  0.568634  0.587171  0.605459  0.635223  0.000851\n",
      "t_subj.41            0.339006  0.016097  0.302634  0.329279  0.340675  0.350614    0.3654  0.000641\n",
      "t_subj.42            0.365564   0.04074  0.274679  0.342068  0.369054  0.393849  0.434761  0.001851\n",
      "t_subj.43            0.360558   0.02392  0.310514  0.346624   0.36142  0.375629  0.404535  0.000553\n",
      "t_subj.44            0.546713  0.020397  0.502074  0.533626  0.548106  0.561398  0.582318  0.000645\n",
      "t_subj.45            0.275733  0.032978  0.202962  0.255684   0.27753  0.297561  0.335242  0.000702\n",
      "t_subj.46            0.307107  0.033899  0.234112  0.284738  0.310094   0.33232   0.36376  0.001477\n",
      "t_subj.47            0.361367  0.017209  0.324072  0.350623  0.362705  0.373852  0.390416  0.000568\n",
      "t_subj.48            0.334496  0.020652  0.286214   0.32277  0.336316   0.34919  0.368618  0.000966\n",
      "t_subj.49            0.499429  0.024622  0.447503  0.485036  0.500108  0.515708   0.54542  0.000664\n",
      "z                    0.433981  0.013346  0.408038  0.424793  0.434253  0.442811  0.460539  0.000516\n",
      "z_std                0.305678  0.025148  0.256407  0.289016  0.305644  0.322465  0.357064  0.000966\n",
      "z_subj.1              0.41934  0.027498  0.364563  0.400919  0.419761  0.438607  0.473377   0.00068\n",
      "z_subj.2             0.393192  0.046316  0.305783   0.36114  0.393206  0.424206  0.482814  0.002453\n",
      "z_subj.3             0.383533  0.036453  0.313763   0.35893  0.381813  0.407205  0.458221  0.001392\n",
      "z_subj.4             0.564997  0.027293  0.511881   0.54657   0.56448  0.583337  0.618969  0.000648\n",
      "z_subj.5               0.3271  0.060247  0.220401  0.285664  0.323471  0.365359  0.458858  0.003024\n",
      "z_subj.6             0.335112  0.048312  0.247829  0.301229  0.332853   0.36695  0.438159  0.002991\n",
      "z_subj.7              0.34556  0.050362  0.252251   0.31068  0.344238  0.380383  0.446983  0.002946\n",
      "z_subj.8             0.571689  0.024505  0.523519  0.554912  0.571779  0.588045  0.619403  0.000576\n",
      "z_subj.9             0.426055  0.043551  0.344779   0.39512  0.425298  0.456007   0.51312  0.001789\n",
      "z_subj.10             0.42849  0.033605  0.363566  0.405494  0.427694  0.450949  0.495992   0.00086\n",
      "z_subj.11            0.481268  0.036313  0.409763  0.456629  0.481361  0.505512  0.554508  0.001192\n",
      "z_subj.12            0.672101  0.026663  0.617981  0.654945  0.672939   0.69022   0.72213  0.000795\n",
      "z_subj.13            0.414185  0.035258  0.345732  0.390023  0.413044  0.438125  0.484213  0.001423\n",
      "z_subj.14            0.437995   0.04224  0.354447  0.408979  0.437845   0.46688   0.52019  0.001576\n",
      "z_subj.15            0.480426   0.03462  0.414534  0.456236  0.480176  0.503324  0.551224  0.001009\n",
      "z_subj.16            0.425083  0.040363  0.349928  0.396177  0.424838  0.452269  0.508766   0.00186\n",
      "z_subj.17            0.281377  0.043579  0.197954  0.251299  0.281478  0.310282  0.368622   0.00263\n",
      "z_subj.18             0.41486  0.032029  0.353597  0.393528  0.414124  0.435416    0.4813  0.001014\n",
      "z_subj.19            0.440278  0.030321  0.380292  0.420474  0.440004  0.460647  0.499835  0.000707\n",
      "z_subj.20            0.359062  0.071283  0.227986  0.307645  0.356165  0.408873  0.501905  0.002353\n",
      "z_subj.21            0.462489  0.038021   0.39118  0.437534  0.461287  0.487779  0.540549  0.001371\n",
      "z_subj.22            0.285563   0.03617  0.217517  0.262106  0.283556  0.307717  0.363599  0.001783\n",
      "z_subj.23            0.469327  0.039271  0.392391   0.44277  0.469752  0.495854   0.54577  0.001472\n",
      "z_subj.24            0.369273  0.071118  0.235924  0.320853  0.367169  0.414199  0.519134  0.002868\n",
      "z_subj.25            0.461781  0.032306  0.400162  0.439667  0.460766  0.484236  0.524715   0.00087\n",
      "z_subj.26              0.5709  0.027871  0.514904  0.552591  0.570756  0.589605  0.626406  0.000607\n",
      "z_subj.27            0.484992  0.031797    0.4217  0.463033  0.485089  0.506726   0.54665  0.000819\n",
      "z_subj.28            0.600256  0.027204   0.54674  0.581204  0.599974  0.618707  0.653387  0.000704\n",
      "z_subj.29            0.315552  0.047957  0.229856  0.280433  0.313755   0.34784  0.414577  0.002506\n",
      "z_subj.30            0.429179  0.046168  0.343169  0.397942  0.427439  0.458494  0.527627  0.002228\n",
      "z_subj.31            0.424119  0.040092  0.349691  0.395885  0.423683  0.449715   0.50297  0.001849\n",
      "z_subj.32            0.326441   0.04034  0.252483  0.298275  0.324265  0.353483  0.408331  0.001903\n",
      "z_subj.33            0.390061  0.049667  0.299187  0.355522  0.388399  0.423244  0.489938  0.002485\n",
      "z_subj.34            0.396152  0.031728   0.33626  0.374477  0.395053  0.417743  0.459053  0.000917\n",
      "z_subj.35            0.534224  0.031406  0.472644   0.51241  0.534342  0.555897  0.596861  0.000876\n",
      "z_subj.36            0.414866  0.055954  0.311661   0.37637  0.411667  0.451376   0.53369  0.003359\n",
      "z_subj.37            0.513994  0.026885  0.460719  0.495686  0.514034  0.532414  0.568062  0.000538\n",
      "z_subj.38            0.339967  0.043815   0.25908  0.310976  0.338023  0.366243  0.435472  0.002191\n",
      "z_subj.39            0.501842  0.034574  0.430161  0.479471  0.503921  0.525644   0.56415  0.000991\n",
      "z_subj.40            0.605604  0.026633  0.552512  0.587906  0.605636  0.623835  0.657656  0.000823\n",
      "z_subj.41            0.358576  0.039181  0.285682  0.330749  0.356566  0.384967   0.43812  0.001812\n",
      "z_subj.42            0.452379  0.054594   0.34908  0.414842  0.450743  0.489276   0.56118  0.002837\n",
      "z_subj.43            0.568364   0.03005  0.506497  0.548512  0.569317  0.588868  0.627073  0.000743\n",
      "z_subj.44            0.416982  0.030503  0.358675  0.396372  0.416825   0.43747  0.477412  0.000961\n",
      "z_subj.45            0.518839  0.032716  0.452653  0.496866  0.519464  0.540916    0.5817  0.000759\n",
      "z_subj.46            0.381405   0.04311  0.300205  0.350938  0.379637  0.409478  0.471403  0.001982\n",
      "z_subj.47            0.371771  0.036819  0.303201  0.346264  0.370723  0.395967  0.446586  0.001456\n",
      "z_subj.48            0.379708  0.053602  0.285943  0.341565   0.37635  0.415742  0.492907  0.003043\n",
      "z_subj.49            0.403148  0.034327  0.336694  0.379855  0.402878  0.426328  0.473215  0.000982\n",
      "v_Intercept         -0.412358   0.16294  -0.72896 -0.519782 -0.409493 -0.303061 -0.089248  0.003891\n",
      "v_Intercept_std      1.055039  0.126564  0.836388  0.966592  1.045416  1.132436   1.33109  0.004698\n",
      "v_Intercept_subj.1   0.365087  0.242236 -0.099567  0.205563  0.355248  0.522888  0.849098   0.01138\n",
      "v_Intercept_subj.2  -0.297545  0.350558 -0.979218 -0.542746 -0.310502 -0.055366  0.383872  0.019861\n",
      "v_Intercept_subj.3   0.467197  0.205913  0.050775  0.334974  0.470728  0.605439  0.855091  0.009737\n",
      "v_Intercept_subj.4   0.143803  0.260388 -0.379158 -0.025491   0.14532  0.319577  0.663581  0.011374\n",
      "v_Intercept_subj.5  -1.045359  0.552746 -2.177685 -1.405216 -1.034633 -0.676961  0.026205  0.020623\n",
      "v_Intercept_subj.6  -2.511658  0.417856 -3.311009 -2.795182 -2.511251 -2.226737 -1.672468   0.02608\n",
      "v_Intercept_subj.7  -0.968091  0.362941 -1.664372 -1.225235 -0.965938 -0.723704 -0.242553   0.01382\n",
      "v_Intercept_subj.8    0.10754  0.245895 -0.372318 -0.060485   0.10782  0.271876  0.593048  0.011262\n",
      "v_Intercept_subj.9   -0.40884  0.247573  -0.93719 -0.566165 -0.396241 -0.232978  0.029313  0.013946\n",
      "v_Intercept_subj.10  0.145664  0.158322 -0.161502  0.038828   0.14826  0.256121  0.443283  0.007239\n",
      "v_Intercept_subj.11 -0.206224   0.29732 -0.768705 -0.407093 -0.197704  0.000812   0.37673  0.018009\n",
      "v_Intercept_subj.12 -0.234899  0.229656 -0.700463 -0.385032 -0.232706 -0.082336  0.208425   0.01138\n",
      "v_Intercept_subj.13 -0.110696  0.283621   -0.6615 -0.301398 -0.113286  0.078124  0.447652  0.012626\n",
      "v_Intercept_subj.14 -0.742224   0.30074 -1.350354  -0.93932  -0.74067  -0.54454 -0.148585  0.013323\n",
      "v_Intercept_subj.15 -0.256262  0.229836 -0.699128 -0.413156 -0.263047 -0.099666  0.210175  0.011751\n",
      "v_Intercept_subj.16 -0.186926  0.298898 -0.816995 -0.391578 -0.171264  0.022159  0.363522  0.015765\n",
      "v_Intercept_subj.17 -2.778529  0.485186  -3.73637 -3.097801 -2.781785 -2.436129 -1.882256  0.026133\n",
      "v_Intercept_subj.18  0.569295  0.237691  0.094784  0.409566  0.572638  0.728871  1.042802  0.010156\n",
      "v_Intercept_subj.19   0.41105  0.265752 -0.101399  0.232951  0.410324   0.59016  0.940384  0.011875\n",
      "v_Intercept_subj.20 -0.969297  0.748501 -2.448644 -1.464574 -0.948793 -0.482471  0.507844   0.01823\n",
      "v_Intercept_subj.21    0.6926  0.301341  0.099051  0.490647  0.699931  0.895606   1.28255  0.012247\n",
      "v_Intercept_subj.22   0.22949  0.283242 -0.328182   0.03573  0.231096  0.422161  0.778508  0.011539\n",
      "v_Intercept_subj.23  0.487774  0.313811 -0.128527   0.28232  0.489276  0.698338   1.10758  0.014091\n",
      "v_Intercept_subj.24 -0.854021  0.678986 -2.196548 -1.309501 -0.848877 -0.403065  0.471154  0.017746\n",
      "v_Intercept_subj.25  0.229543     0.286 -0.328989  0.038636  0.229108  0.419799  0.794698   0.01288\n",
      "v_Intercept_subj.26 -0.448322  0.283913 -1.033452 -0.632793 -0.439427 -0.252214  0.077432  0.014065\n",
      "v_Intercept_subj.27  0.586158  0.202613  0.203749  0.451109  0.580986  0.711566   1.01161  0.010224\n",
      "v_Intercept_subj.28 -0.120325  0.231629 -0.580921 -0.282037 -0.119489  0.049964  0.316309  0.011941\n",
      "v_Intercept_subj.29  -1.43309  0.356336 -2.091086 -1.685773 -1.434579 -1.190608 -0.725943  0.018992\n",
      "v_Intercept_subj.30  -1.14736   0.44714 -2.076063 -1.440344 -1.117341 -0.809753 -0.379381  0.028438\n",
      "v_Intercept_subj.31 -1.888863  0.406801  -2.71155  -2.16216  -1.89003 -1.601473 -1.115397  0.021749\n",
      "v_Intercept_subj.32 -0.499636  0.372007 -1.214614 -0.751468 -0.499672 -0.243312  0.216049  0.015944\n",
      "v_Intercept_subj.33 -2.665699  0.418833 -3.468031  -2.94765 -2.673306 -2.386875 -1.825927  0.024384\n",
      "v_Intercept_subj.34  1.616809  0.272544  1.103153  1.426328  1.609428  1.802608   2.16071  0.014078\n",
      "v_Intercept_subj.35 -0.802793  0.342403 -1.466017 -1.025901 -0.803715 -0.579705 -0.117793  0.019068\n",
      "v_Intercept_subj.36  -2.23658   0.44001 -3.071239 -2.539715 -2.225047 -1.938262 -1.368432  0.026352\n",
      "v_Intercept_subj.37  0.162052  0.226409  -0.30128  0.011699  0.164861  0.314732  0.601654  0.011183\n",
      "v_Intercept_subj.38 -0.476729  0.285786 -1.015738 -0.681138  -0.47592 -0.276292  0.080941  0.013401\n",
      "v_Intercept_subj.39 -0.115012  0.312331 -0.747017 -0.322077 -0.112039  0.093506  0.509223   0.01578\n",
      "v_Intercept_subj.40 -0.670798  0.236539 -1.154318 -0.827803 -0.665513 -0.509214 -0.230796   0.01155\n",
      "v_Intercept_subj.41  0.060814  0.309782  -0.56572  -0.13499   0.07159  0.274439  0.628514  0.012634\n",
      "v_Intercept_subj.42 -1.782014  0.341644 -2.423208  -2.03226 -1.778562 -1.542033 -1.125113  0.019432\n",
      "v_Intercept_subj.43  1.530871  0.274167  1.000287  1.347497  1.531188  1.711517  2.082498  0.014895\n",
      "v_Intercept_subj.44  0.166353  0.266755 -0.389717 -0.010472  0.160936  0.346909  0.679358  0.012694\n",
      "v_Intercept_subj.45  0.423951  0.239593 -0.046138  0.255397  0.426618   0.58624  0.897409  0.011907\n",
      "v_Intercept_subj.46 -1.205896  0.267807 -1.726967 -1.393277 -1.203586 -1.023099 -0.698559  0.013626\n",
      "v_Intercept_subj.47  0.031751  0.282195  -0.53471 -0.155539  0.042995  0.220116  0.593327  0.012664\n",
      "v_Intercept_subj.48 -1.515755  0.363478  -2.22067 -1.769307 -1.519477 -1.269165 -0.803997  0.017958\n",
      "v_Intercept_subj.49  -0.24036  0.264409 -0.741814 -0.415115 -0.243913   -0.0635  0.271422  0.013865\n",
      "v_gain               0.011347  0.002639  0.006185  0.009587  0.011398  0.013112  0.016443  0.000057\n",
      "v_gain_std           0.017316  0.002145  0.013524  0.015771  0.017149  0.018667  0.021938  0.000053\n",
      "v_gain_subj.1        0.029776  0.003857  0.022452  0.027265  0.029669  0.032209  0.038063  0.000171\n",
      "v_gain_subj.2        0.009286  0.004403  0.000949  0.006297  0.009375  0.012238  0.017832  0.000167\n",
      "v_gain_subj.3       -0.001795  0.003572 -0.008882 -0.004162 -0.001796   0.00056  0.005293  0.000138\n",
      "v_gain_subj.4        0.041113  0.005478  0.031095  0.037406  0.040844   0.04456  0.052747  0.000303\n",
      "v_gain_subj.5       -0.004203  0.009135 -0.022799 -0.010276 -0.004257  0.001721   0.01362  0.000252\n",
      "v_gain_subj.6        0.003098  0.004229 -0.005118  0.000263   0.00309  0.005852  0.011507  0.000162\n",
      "v_gain_subj.7       -0.004009  0.007418 -0.018316 -0.009217 -0.004066  0.001097  0.010374  0.000283\n",
      "v_gain_subj.8        0.046761  0.004479  0.038237   0.04379  0.046661  0.049681  0.055854   0.00021\n",
      "v_gain_subj.9        0.000034  0.003069   -0.0059  -0.00203 -0.000021  0.002185   0.00591  0.000107\n",
      "v_gain_subj.10      -0.000508   0.00267 -0.005829 -0.002263 -0.000511  0.001303  0.004699  0.000106\n",
      "v_gain_subj.11       0.009766  0.003457  0.002914  0.007476  0.009797  0.012128  0.016489  0.000148\n",
      "v_gain_subj.12       0.030667  0.004194  0.022611  0.027701   0.03058  0.033541  0.038961  0.000191\n",
      "v_gain_subj.13       0.024333  0.004917  0.014938   0.02086   0.02441  0.027681   0.03403  0.000204\n",
      "v_gain_subj.14       0.015692  0.004262  0.007286  0.012712   0.01583  0.018702  0.023737  0.000177\n",
      "v_gain_subj.15       0.011675  0.003389  0.004849   0.00936  0.011813  0.013986  0.018024  0.000145\n",
      "v_gain_subj.16       0.004913  0.003749 -0.002473  0.002403  0.004872  0.007325  0.012378  0.000139\n",
      "v_gain_subj.17       0.006637  0.005319 -0.003516  0.002885  0.006603  0.010381  0.016905  0.000211\n",
      "v_gain_subj.18       0.013464  0.003526  0.006505  0.011024  0.013511  0.015847   0.02044  0.000138\n",
      "v_gain_subj.19       0.001573  0.004511 -0.007157 -0.001654  0.001508   0.00459  0.010577  0.000152\n",
      "v_gain_subj.20       0.013674  0.013281 -0.012358  0.004651  0.013973  0.022981  0.039855  0.000354\n",
      "v_gain_subj.21       -0.00123  0.005408 -0.011802 -0.004794 -0.001352   0.00238  0.009463  0.000203\n",
      "v_gain_subj.22      -0.007038  0.005556 -0.018143 -0.010676 -0.006945 -0.003315  0.003718   0.00019\n",
      "v_gain_subj.23      -0.005029  0.004684  -0.01402 -0.008246 -0.005137 -0.001955  0.004206  0.000171\n",
      "v_gain_subj.24      -0.022437  0.015325 -0.054168 -0.032322 -0.022283  -0.01222  0.007072  0.000402\n",
      "v_gain_subj.25       0.006023  0.004648 -0.002827  0.002951  0.005818  0.009109  0.015487  0.000181\n",
      "v_gain_subj.26       0.041929  0.005681  0.031522  0.038157  0.041513   0.04538  0.054468  0.000313\n",
      "v_gain_subj.27       0.029852  0.003547   0.02311  0.027361  0.029895  0.032226  0.036884  0.000176\n",
      "v_gain_subj.28       0.039204  0.003968  0.031294  0.036551  0.039264  0.041846  0.047169  0.000186\n",
      "v_gain_subj.29      -0.005342  0.004976 -0.015144 -0.008567 -0.005207 -0.001921  0.004283  0.000162\n",
      "v_gain_subj.30       0.006209  0.004336 -0.002307  0.003362  0.006272  0.009096  0.014644  0.000177\n",
      "v_gain_subj.31       0.030459   0.00478  0.021505  0.027231  0.030362  0.033619  0.040283    0.0002\n",
      "v_gain_subj.32       0.009178  0.005364 -0.001426   0.00562  0.009108  0.012845  0.019657  0.000179\n",
      "v_gain_subj.33      -0.001042  0.004004  -0.00921 -0.003617 -0.000971  0.001667  0.006716  0.000138\n",
      "v_gain_subj.34       0.011153  0.004883  0.002108  0.007801  0.011076   0.01437  0.020948  0.000247\n",
      "v_gain_subj.35       0.014998  0.004255  0.006903   0.01207  0.014934  0.017887  0.023603  0.000152\n",
      "v_gain_subj.36      -0.004235  0.005099 -0.013982 -0.007826 -0.004234 -0.000753  0.005811   0.00019\n",
      "v_gain_subj.37       0.027572  0.004019  0.019788  0.024718  0.027576  0.030355  0.035404  0.000196\n",
      "v_gain_subj.38      -0.006098  0.004435  -0.01474  -0.00907 -0.006036  -0.00321   0.00272  0.000151\n",
      "v_gain_subj.39       0.031174  0.004958   0.02171  0.027786  0.031223  0.034258  0.041476  0.000212\n",
      "v_gain_subj.40       0.046562  0.005239  0.036339  0.043003   0.04651  0.050173  0.056732  0.000317\n",
      "v_gain_subj.41      -0.004683  0.005697 -0.016116 -0.008343 -0.004669 -0.000892    0.0063  0.000215\n",
      "v_gain_subj.42       0.004713  0.003744 -0.002633  0.002119  0.004846    0.0072  0.011917  0.000153\n",
      "v_gain_subj.43       0.014493  0.003458  0.007877  0.012086  0.014465  0.016907  0.021321   0.00014\n",
      "v_gain_subj.44       0.021646  0.004067  0.013726  0.018885  0.021541  0.024389  0.029791  0.000182\n",
      "v_gain_subj.45       0.010464  0.003743  0.003252  0.007824  0.010507  0.012947  0.017573  0.000155\n",
      "v_gain_subj.46      -0.002848  0.003456 -0.009534 -0.005227 -0.002938 -0.000486  0.003964  0.000132\n",
      "v_gain_subj.47       0.001666  0.004272 -0.006444 -0.001214  0.001621  0.004492  0.010065  0.000152\n",
      "v_gain_subj.48        0.00283  0.005491 -0.008425 -0.000624  0.002916  0.006489  0.013531  0.000202\n",
      "v_gain_subj.49       0.013385  0.003456  0.006728  0.011054  0.013375  0.015733  0.020159  0.000136\n",
      "v_loss               0.020238  0.002334  0.015639  0.018702   0.02026  0.021823   0.02486  0.000056\n",
      "v_loss_std           0.015578   0.00182   0.01234  0.014278  0.015468   0.01676  0.019343  0.000059\n",
      "v_loss_subj.1        0.034251  0.003921   0.02683  0.031577  0.034018  0.036874  0.042079  0.000207\n",
      "v_loss_subj.2        0.021283  0.004792   0.01215  0.017921  0.021237  0.024539  0.030469  0.000235\n",
      "v_loss_subj.3        0.022716  0.003653  0.015555  0.020246  0.022782  0.025182  0.029621   0.00016\n",
      "v_loss_subj.4        0.041364  0.005312  0.031307   0.03777  0.041153   0.04474  0.052174  0.000303\n",
      "v_loss_subj.5        0.016189  0.008698 -0.001113  0.010461  0.016096  0.022022  0.033526  0.000296\n",
      "v_loss_subj.6        -0.00971  0.004803 -0.019183 -0.012837 -0.009654 -0.006483 -0.000658   0.00026\n",
      "v_loss_subj.7        0.017855   0.00746  0.004189  0.012638  0.017624  0.022767  0.032561  0.000319\n",
      "v_loss_subj.8        0.043713  0.004246  0.035726  0.040771  0.043669  0.046538  0.052336  0.000224\n",
      "v_loss_subj.9        0.009815  0.003486  0.002918  0.007573  0.009775  0.012152  0.016928  0.000166\n",
      "v_loss_subj.10       0.011637  0.002468  0.006903   0.00989  0.011654  0.013363  0.016424  0.000112\n",
      "v_loss_subj.11       0.021081  0.003953  0.013239  0.018506   0.02116  0.023771  0.028632   0.00023\n",
      "v_loss_subj.12        0.02691  0.003892  0.019321  0.024356  0.026874  0.029397  0.034774  0.000204\n",
      "v_loss_subj.13       0.035659  0.005159  0.025507  0.032207  0.035664   0.03911   0.04563  0.000241\n",
      "v_loss_subj.14       0.020611  0.004467   0.01232  0.017495  0.020488  0.023644  0.029679  0.000188\n",
      "v_loss_subj.15       0.016724  0.003142   0.01074  0.014601  0.016613   0.01885  0.022967   0.00015\n",
      "v_loss_subj.16       0.016817  0.004253  0.008795  0.013818  0.016774  0.019739  0.025161  0.000206\n",
      "v_loss_subj.17       -0.00798  0.005627 -0.019315 -0.011835 -0.007964 -0.004005  0.002806   0.00027\n",
      "v_loss_subj.18       0.031028  0.003945  0.023465  0.028269  0.030993  0.033604  0.038908  0.000193\n",
      "v_loss_subj.19       0.004448  0.004235 -0.003872  0.001682   0.00438  0.007307  0.012709  0.000186\n",
      "v_loss_subj.20       0.020008  0.012539 -0.003624  0.011037  0.019816  0.028713  0.045588   0.00032\n",
      "v_loss_subj.21       0.039871  0.005497  0.029103  0.036144  0.039878  0.043494  0.050734  0.000227\n",
      "v_loss_subj.22       0.020575  0.004393  0.012107  0.017647  0.020634  0.023435  0.029427  0.000172\n",
      "v_loss_subj.23        0.03196  0.004583  0.023147  0.028805  0.031878  0.035015  0.041018  0.000185\n",
      "v_loss_subj.24       0.016131  0.010029 -0.003666  0.009565  0.016065  0.022693  0.036296  0.000255\n",
      "v_loss_subj.25       0.027599  0.004411  0.018777  0.024749  0.027533  0.030521  0.036386   0.00018\n",
      "v_loss_subj.26       0.028449  0.004553  0.019736  0.025319  0.028362  0.031553  0.037136  0.000244\n",
      "v_loss_subj.27        0.04504  0.004516  0.036821   0.04189  0.044883  0.048039  0.054252  0.000253\n",
      "v_loss_subj.28       0.036252   0.00411  0.028537  0.033507  0.036225  0.039022  0.044477  0.000203\n",
      "v_loss_subj.29       -0.00658  0.004597 -0.015273 -0.009767 -0.006683 -0.003514  0.002681  0.000239\n",
      "v_loss_subj.30       0.011316  0.005602 -0.000169   0.00762  0.011516  0.015206  0.021641  0.000329\n",
      "v_loss_subj.31        0.02142  0.005251  0.011336   0.01774  0.021465  0.025069  0.031652  0.000249\n",
      "v_loss_subj.32       0.026342  0.005448  0.015848  0.022629  0.026407   0.03004  0.036931  0.000224\n",
      "v_loss_subj.33      -0.014388  0.004616  -0.02329 -0.017629  -0.01438 -0.011137 -0.005404  0.000255\n",
      "v_loss_subj.34       0.043093  0.006016  0.032707  0.038707  0.042598  0.046957  0.055832  0.000365\n",
      "v_loss_subj.35        0.01933  0.004789  0.010256  0.015943   0.01921  0.022636  0.028725  0.000242\n",
      "v_loss_subj.36        0.00087   0.00518 -0.009425 -0.002738  0.001099  0.004543  0.010459  0.000258\n",
      "v_loss_subj.37       0.025038  0.003907   0.01774  0.022358  0.024849  0.027602  0.033258  0.000201\n",
      "v_loss_subj.38        0.00933   0.00429  0.001032  0.006401  0.009196  0.012267  0.017914  0.000188\n",
      "v_loss_subj.39       0.031213  0.004689  0.022109  0.028049  0.031182  0.034313  0.040505  0.000232\n",
      "v_loss_subj.40       0.029797  0.004159  0.021711  0.026871  0.029816  0.032582  0.038097  0.000232\n",
      "v_loss_subj.41        0.01981  0.004817  0.010386  0.016588  0.019813   0.02305  0.029288  0.000204\n",
      "v_loss_subj.42      -0.000392  0.003798 -0.007621 -0.002979 -0.000339  0.002173  0.006963  0.000201\n",
      "v_loss_subj.43       0.033592  0.004094   0.02622  0.030667   0.03332  0.036449  0.042017  0.000226\n",
      "v_loss_subj.44       0.033357  0.004111  0.025304   0.03064  0.033394  0.036168  0.041211  0.000191\n",
      "v_loss_subj.45       0.015034  0.003919  0.007472  0.012355  0.014966  0.017661  0.022786  0.000203\n",
      "v_loss_subj.46      -0.001158  0.003456 -0.007628  -0.00351 -0.001152  0.001049  0.005876  0.000167\n",
      "v_loss_subj.47       0.019753   0.00456  0.010554   0.01672   0.01983  0.022865  0.028436  0.000205\n",
      "v_loss_subj.48       0.015808  0.005088  0.006165  0.012398  0.015652  0.019187  0.026113  0.000226\n",
      "v_loss_subj.49       0.017766  0.003755  0.010793  0.015086  0.017635  0.020302  0.025269  0.000181\n",
      "DIC: 12392.352279\n",
      "deviance: 12144.586010\n",
      "pD: 247.766269\n"
     ]
    }
   ],
   "source": [
    "m.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c0ab0fe6-24dd-4a9b-ab9b-4e7cbf5c38f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "modelParamsDF = m.nodes_db\n",
    "modelParamsDF.to_csv('savedModels/{}/{}_nodes.csv'.format(modelName, modelName))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bd4eb0ae-9565-4d73-bdad-4b1664f4ccae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group level mean of lamdba is:  1.784\n",
      "2.5% percentile for beta_L:  0.016\n",
      "97.5% percentile for beta_G:  0.016\n"
     ]
    }
   ],
   "source": [
    "# group level mean of lambda\n",
    "groupLevelMeanOfLambda = modelParamsDF.loc['v_loss', 'mean']/modelParamsDF.loc['v_gain', 'mean']\n",
    "print(\"group level mean of lamdba is: \", round(groupLevelMeanOfLambda, 3))\n",
    "# 95% CI for beta_G, beta_L\n",
    "print(\"2.5% percentile for beta_L: \", round(modelParamsDF.loc['v_loss', '2.5q'], 3))\n",
    "print(\"97.5% percentile for beta_G: \", round(modelParamsDF.loc['v_gain', '97.5q'], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4f50a479-70c3-4531-bfe2-1b0ef01310c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people with beta_L > beta_G =  37\n",
      "Number of people with 95% CI of beta_L > beta_G =  11\n",
      "Average lambda over all individuals = 5.552 (SD = 41.03)\n"
     ]
    }
   ],
   "source": [
    "# how many participants have beta_L > beta_G, how many have the 95% CI greater?\n",
    "# participant level mean (SD) of lambda\n",
    "numSubjects = 49\n",
    "numLambdaMean = 0\n",
    "numLambdaCI = 0\n",
    "allParticipantLambdas = []\n",
    "\n",
    "for subjectIndex in range(1, numSubjects+1):\n",
    "    try:\n",
    "        beta_gain = modelParamsDF.loc['v_gain_subj.{}'.format(subjectIndex), 'mean']\n",
    "        beta_loss = modelParamsDF.loc['v_loss_subj.{}'.format(subjectIndex), 'mean']\n",
    "        beta_L_lowerBound = modelParamsDF.loc['v_loss_subj.{}'.format(subjectIndex), '2.5q']\n",
    "        beta_G_upperBound = modelParamsDF.loc['v_gain_subj.{}'.format(subjectIndex), '97.5q']\n",
    "\n",
    "        if beta_loss > beta_gain:\n",
    "            numLambdaMean += 1\n",
    "        if beta_L_lowerBound > beta_G_upperBound:\n",
    "            numLambdaCI += 1\n",
    "\n",
    "        lambdaForThisParticipant = beta_loss / beta_gain\n",
    "        allParticipantLambdas.append(lambdaForThisParticipant)\n",
    "\n",
    "    except KeyError:\n",
    "        print(f\"Data for participant {subjectIndex} is missing.\")\n",
    "        continue  # Skip the rest of the loop and move to the next iteration\n",
    "\n",
    "print(\"Number of people with beta_L > beta_G = \", round(numLambdaMean, 3))\n",
    "print(\"Number of people with 95% CI of beta_L > beta_G = \", numLambdaCI)\n",
    "print(\"Average lambda over all individuals = {} (SD = {})\".format(round(np.mean(allParticipantLambdas), 3), round(np.std(allParticipantLambdas), 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "19f792e3-4e29-4735-a97a-43a18bbceded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people with beta_L > beta_G =  37\n",
      "Participants with beta_L > beta_G:  [1, 2, 3, 4, 5, 7, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 30, 32, 34, 35, 36, 38, 39, 41, 43, 44, 45, 46, 47, 48, 49]\n",
      "Number of people with 95% CI of beta_L > beta_G =  11\n",
      "Participants with 95% CI of beta_L > beta_G:  [3, 10, 18, 21, 22, 23, 25, 34, 41, 43, 47]\n",
      "Average lambda over all individuals = 5.552 (SD = 41.03)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "numSubjects = 49\n",
    "numLambdaMean = 0\n",
    "numLambdaCI = 0\n",
    "allParticipantLambdas = []\n",
    "\n",
    "# Lists to store the indices of the participants meeting the conditions\n",
    "participantsWithBetaLGreater = []\n",
    "participantsWith95CIGreater = []\n",
    "\n",
    "for subjectIndex in range(1, numSubjects+1):\n",
    "    try:\n",
    "        beta_gain = modelParamsDF.loc['v_gain_subj.{}'.format(subjectIndex), 'mean']\n",
    "        beta_loss = modelParamsDF.loc['v_loss_subj.{}'.format(subjectIndex), 'mean']\n",
    "        beta_L_lowerBound = modelParamsDF.loc['v_loss_subj.{}'.format(subjectIndex), '2.5q']\n",
    "        beta_G_upperBound = modelParamsDF.loc['v_gain_subj.{}'.format(subjectIndex), '97.5q']\n",
    "    \n",
    "        if beta_loss > beta_gain:\n",
    "            numLambdaMean += 1\n",
    "            participantsWithBetaLGreater.append(subjectIndex)\n",
    "        if beta_L_lowerBound > beta_G_upperBound:\n",
    "            numLambdaCI += 1\n",
    "            participantsWith95CIGreater.append(subjectIndex)\n",
    "        \n",
    "        lambdaForThisParticipant = beta_loss/beta_gain\n",
    "        allParticipantLambdas.append(lambdaForThisParticipant)\n",
    "        \n",
    "    except KeyError:\n",
    "        print(f\"Data for participant {subjectIndex} is missing.\")\n",
    "        continue  # Skip the rest of the loop and move to the next iteration\n",
    "print(\"Number of people with beta_L > beta_G = \", round(numLambdaMean, 3))\n",
    "print(\"Participants with beta_L > beta_G: \", participantsWithBetaLGreater)\n",
    "print(\"Number of people with 95% CI of beta_L > beta_G = \", numLambdaCI)\n",
    "print(\"Participants with 95% CI of beta_L > beta_G: \", participantsWith95CIGreater)\n",
    "print(\"Average lambda over all individuals = {} (SD = {})\".format(round(np.mean(allParticipantLambdas), 3), round(np.std(allParticipantLambdas), 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c2e337df-e64e-4343-a62b-a3839cc281f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people with beta_L > beta_G =  25\n",
      "Number of people with 95% CI of beta_L > beta_G =  5\n",
      "Average lambda over all individuals = 11.04 (SD = 49.389)\n"
     ]
    }
   ],
   "source": [
    "# how many participants have beta_L > beta_G, how many have the 95% CI greater?\n",
    "# participant level mean (SD) of lambda\n",
    "numSubjects = 49\n",
    "numLambdaMean = 0\n",
    "numLambdaCI = 0\n",
    "allParticipantLambdas = []\n",
    "\n",
    "for subjectIndex in range(1, numSubjects+1):\n",
    "    try:\n",
    "        beta_gain = modelParamsDF.loc['v_gain_subj.{}'.format(subjectIndex), 'mean']\n",
    "        beta_loss = modelParamsDF.loc['v_loss_subj.{}'.format(subjectIndex), 'mean']\n",
    "        \n",
    "        # Skip if either beta_gain or beta_loss is negative\n",
    "        if beta_gain <= 0 or beta_loss <= 0:\n",
    "            continue\n",
    "\n",
    "        beta_L_lowerBound = modelParamsDF.loc['v_loss_subj.{}'.format(subjectIndex), '2.5q']\n",
    "        beta_G_upperBound = modelParamsDF.loc['v_gain_subj.{}'.format(subjectIndex), '97.5q']\n",
    "\n",
    "        if beta_loss > beta_gain:\n",
    "            numLambdaMean += 1\n",
    "        if beta_L_lowerBound > beta_G_upperBound:\n",
    "            numLambdaCI += 1\n",
    "\n",
    "        lambdaForThisParticipant = beta_loss / beta_gain\n",
    "        allParticipantLambdas.append(lambdaForThisParticipant)\n",
    "\n",
    "    except KeyError:\n",
    "        print(f\"Data for participant {subjectIndex} is missing.\")\n",
    "        continue  # Skip the rest of the loop and move to the next iteration\n",
    "\n",
    "print(\"Number of people with beta_L > beta_G = \", round(numLambdaMean, 3))\n",
    "print(\"Number of people with 95% CI of beta_L > beta_G = \", numLambdaCI)\n",
    "print(\"Average lambda over all individuals = {} (SD = {})\".format(round(np.mean(allParticipantLambdas), 3), round(np.std(allParticipantLambdas), 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "24e78fb9-9200-46d0-af4e-47695dca5413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta_L mean: 0.02\n",
      "beta_L 2.5q: 0.016\n",
      "beta_L 97.5q: 0.025\n",
      "beta_L median 0.02\n",
      "beta_L SD 0.002\n",
      "beta_G mean: 0.011\n",
      "beta_G 2.5q: 0.006\n",
      "beta_G 97.5q: 0.016\n",
      "beta_G median 0.011\n",
      "beta_G SD 0.003\n"
     ]
    }
   ],
   "source": [
    "print(\"beta_L mean:\", round(modelParamsDF.loc['v_loss', 'mean'], 3))\n",
    "print(\"beta_L 2.5q:\", round(modelParamsDF.loc['v_loss', '2.5q'], 3))\n",
    "print(\"beta_L 97.5q:\", round(modelParamsDF.loc['v_loss', '97.5q'], 3))\n",
    "print(\"beta_L median\", round(modelParamsDF.loc['v_loss', '50q'], 3))\n",
    "print(\"beta_L SD\", round(modelParamsDF.loc['v_loss', 'std'], 3))\n",
    "\n",
    "print(\"beta_G mean:\", round(modelParamsDF.loc['v_gain', 'mean'], 3))\n",
    "print(\"beta_G 2.5q:\", round(modelParamsDF.loc['v_gain', '2.5q'], 3))\n",
    "print(\"beta_G 97.5q:\", round(modelParamsDF.loc['v_gain', '97.5q'], 3))\n",
    "print(\"beta_G median\", round(modelParamsDF.loc['v_gain', '50q'], 3))\n",
    "print(\"beta_G SD\", round(modelParamsDF.loc['v_gain', 'std'], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1954b4f5-135b-4d91-9146-c434ed9e7d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean value of threshold:  2.2964690439465207\n",
      "confidence interval of gamma:  -0.184 -0.079\n"
     ]
    }
   ],
   "source": [
    "meanA = modelParamsDF.loc['a', 'mean']\n",
    "print(\"mean value of threshold: \", meanA)\n",
    "\n",
    "# 95 CI interval\n",
    "Z_CI_lowerBound = (modelParamsDF.loc['z'.format(subjectIndex), '2.5q'] - 0.5)*2\n",
    "Z_CI_upperBound = (modelParamsDF.loc['z'.format(subjectIndex), '97.5q'] - 0.5)*2\n",
    "print(\"confidence interval of gamma: \", round(Z_CI_lowerBound, 3), round(Z_CI_upperBound, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0c6edc0b-4d8c-4ca6-a0fe-e422bf5525a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean value of pre-valuation bias (gamma) across all participants: -0.129 (SD = 0.174)\n",
      "Number of participants with negative gamma: 38\n",
      "Number of participants with 95% CI of gamma negative:  23\n"
     ]
    }
   ],
   "source": [
    "numSubjects = 49\n",
    "allParticipantsZ = []\n",
    "countGammaMean = 0\n",
    "countGammaCI = 0\n",
    "\n",
    "for participantIndex in range(1, numSubjects+1):\n",
    "    try:\n",
    "        a_participant = modelParamsDF.loc['a_subj.{}'.format(participantIndex), 'mean']\n",
    "        z_participant = (modelParamsDF.loc['z_subj.{}'.format(participantIndex), 'mean'] - 0.5)*2\n",
    "        allParticipantsZ.append(z_participant)\n",
    "        z_upperBound_participant = (modelParamsDF.loc['z_subj.{}'.format(participantIndex), '97.5q'] - 0.5)*2\n",
    "    \n",
    "        if z_upperBound_participant < 0:\n",
    "            countGammaCI += 1\n",
    "        \n",
    "        if z_participant < 0:\n",
    "            countGammaMean += 1\n",
    "    \n",
    "    except KeyError:\n",
    "        print(f\"Data for participant {participantIndex} is missing.\")\n",
    "        continue  # Skip the rest of the loop and move to the next iteration\n",
    "\n",
    "# Calculate the mean and standard deviation after collecting all participant data\n",
    "mean_Z = np.mean(allParticipantsZ)\n",
    "SD_Z = np.std(allParticipantsZ)\n",
    "\n",
    "print(\"Mean value of pre-valuation bias (gamma) across all participants: {} (SD = {})\".format(round(mean_Z, 3), round(SD_Z, 3)))\n",
    "print(\"Number of participants with negative gamma:\", countGammaMean)\n",
    "print(\"Number of participants with 95% CI of gamma negative: \", round(countGammaCI, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0bd683cc-6f15-4918-b47c-0872928dce79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma mean: -0.132\n",
      "gamma 2.5q: -0.184\n",
      "gamma 97.5q: -0.079\n",
      "gamma median -0.131\n",
      "gamma SD 0.027\n"
     ]
    }
   ],
   "source": [
    "print(\"gamma mean:\", round((modelParamsDF.loc['z', 'mean'] - 0.5)*2, 3))\n",
    "print(\"gamma 2.5q:\", round((modelParamsDF.loc['z', '2.5q'] - 0.5)*2, 3))\n",
    "print(\"gamma 97.5q:\", round((modelParamsDF.loc['z', '97.5q'] - 0.5)*2, 3))\n",
    "print(\"gamma median\", round((modelParamsDF.loc['z', '50q'] - 0.5)*2, 3))\n",
    "print(\"gamma SD\", round((modelParamsDF.loc['z', 'std'])*2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "20a88bdf-26ba-4ee8-b533-c84033a0e71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean value of fixed utility bias across all participants: -0.416 (SD = 0.962)\n",
      "Number of participants with negative alpha:  30\n",
      "Number of participants with 95% CI of alpha negative:  14\n",
      "Group-level mean of alpha is:  -0.412\n"
     ]
    }
   ],
   "source": [
    "numSubjects = 49\n",
    "allParticipantsAlphas = []\n",
    "countAlphaMean = 0\n",
    "countAlphaCI = 0\n",
    "\n",
    "for participantIndex in range(1, numSubjects+1):\n",
    "    try:\n",
    "        alpha_participant = modelParamsDF.loc['v_Intercept_subj.{}'.format(participantIndex), 'mean']\n",
    "        allParticipantsAlphas.append(alpha_participant)\n",
    "        alpha_upperBound_participant = modelParamsDF.loc['v_Intercept_subj.{}'.format(participantIndex), '97.5q']\n",
    "    \n",
    "        if alpha_upperBound_participant < 0:\n",
    "            countAlphaCI += 1\n",
    "        \n",
    "        if alpha_participant < 0:\n",
    "            countAlphaMean += 1\n",
    "    \n",
    "    except KeyError:\n",
    "        print(f\"Data for participant {participantIndex} is missing.\")\n",
    "        continue  # Skip the rest of the loop and move to the next iteration\n",
    "\n",
    "# Calculate the mean and standard deviation after collecting all participant data\n",
    "mean_alpha = np.mean(allParticipantsAlphas)\n",
    "SD_alpha = np.std(allParticipantsAlphas)\n",
    "\n",
    "print(\"Mean value of fixed utility bias across all participants: {} (SD = {})\".format(round(mean_alpha, 3), round(SD_alpha, 3)))\n",
    "print(\"Number of participants with negative alpha: \", round(countAlphaMean, 3))\n",
    "print(\"Number of participants with 95% CI of alpha negative: \", round(countAlphaCI, 3))\n",
    "\n",
    "# Print group-level mean of alpha\n",
    "group_level_mean_alpha = modelParamsDF.loc['v_Intercept', 'mean']\n",
    "print(\"Group-level mean of alpha is: \", round(group_level_mean_alpha, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "874e377e-ced0-4374-932d-d9ebd8d40391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha mean: -0.412\n",
      "alpha 2.5q: -0.729\n",
      "alpha 97.5q: -0.089\n",
      "alpha median -0.409\n",
      "alpha SD 0.163\n"
     ]
    }
   ],
   "source": [
    "print(\"alpha mean:\", round(modelParamsDF.loc['v_Intercept', 'mean'], 3))\n",
    "print(\"alpha 2.5q:\", round(modelParamsDF.loc['v_Intercept', '2.5q'], 3))\n",
    "print(\"alpha 97.5q:\", round(modelParamsDF.loc['v_Intercept', '97.5q'], 3))\n",
    "print(\"alpha median\", round(modelParamsDF.loc['v_Intercept', '50q'], 3))\n",
    "print(\"alpha SD\", round(modelParamsDF.loc['v_Intercept', 'std'], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "16752f2b-90a3-4d1c-b17c-7415b2b82ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta mean: 1.148\n",
      "theta 2.5q: 1.08\n",
      "theta 97.5q: 1.223\n",
      "theta median 1.147\n",
      "theta SD 0.037\n"
     ]
    }
   ],
   "source": [
    "print(\"theta mean:\", round(modelParamsDF.loc['a', 'mean']/2, 3))\n",
    "print(\"theta 2.5q:\", round(modelParamsDF.loc['a', '2.5q']/2, 3))\n",
    "print(\"theta 97.5q:\", round(modelParamsDF.loc['a', '97.5q']/2, 3))\n",
    "print(\"theta median\", round(modelParamsDF.loc['a', '50q']/2, 3))\n",
    "print(\"theta SD\", round(modelParamsDF.loc['a', 'std']/2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "941f0636-2161-4f73-b2b2-433ab79cf326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau mean: 0.434\n",
      "tau 2.5q: 0.397\n",
      "tau 97.5q: 0.473\n",
      "tau median 0.434\n",
      "tau SD 0.019\n"
     ]
    }
   ],
   "source": [
    "print(\"tau mean:\", round(modelParamsDF.loc['t', 'mean'], 3))\n",
    "print(\"tau 2.5q:\", round(modelParamsDF.loc['t', '2.5q'], 3))\n",
    "print(\"tau 97.5q:\", round(modelParamsDF.loc['t', '97.5q'], 3))\n",
    "print(\"tau median\", round(modelParamsDF.loc['t', '50q'], 3))\n",
    "print(\"tau SD\", round(modelParamsDF.loc['t', 'std'], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed805801-8fb3-4ab0-be10-28b08c9341e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d699493b-e60b-43aa-8186-3cc56c4fa73b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65de2d61-eb3d-414d-a16a-68cde37a5760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
